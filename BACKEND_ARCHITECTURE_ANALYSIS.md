# Backend Architecture Analysis: Generate Prompts Flow

## Overview
This document explains the complete backend architecture for the "Generate Prompts" button flow, including data generation, storage, and the identified architectural flaws.

---

## 1. URL Analysis ID Generation

### How it's Generated
The `urlAnalysisId` is a MongoDB ObjectId that is automatically generated when a `UrlAnalysis` document is created.

**Location**: `/backend/src/routes/onboarding.js` â†’ `/analyze-website` endpoint (line 358-360)

```javascript
const urlAnalysis = new UrlAnalysis(urlAnalysisData);
await urlAnalysis.save();
// urlAnalysis._id is the urlAnalysisId
```

**Flow**:
1. User submits a website URL via `/onboarding/analyze-website` endpoint
2. Website analysis service analyzes the URL using AI
3. A new `UrlAnalysis` document is created with:
   - `userId`: MongoDB ObjectId reference to User
   - `url`: The analyzed website URL
   - `analysisDate`: Current timestamp
   - `brandContext`: Company/brand information
   - `competitors`: Array of competitor objects (embedded)
   - `topics`: Array of topic objects (embedded)
   - `personas`: Array of persona objects (embedded)
   - `_id`: **This is the urlAnalysisId** (auto-generated by MongoDB)

**Response**: The endpoint returns `urlAnalysisId: urlAnalysis._id` to the frontend (line 444)

---

## 2. Topics, Personas, and Competitors Generation & Storage

### Initial Creation (During Website Analysis)

**Location**: `/backend/src/routes/onboarding.js` â†’ `/analyze-website` endpoint (lines 372-436)

#### 2.1 Competitors Storage
```javascript
// Lines 377-389
analysisResults.competitors.map(comp => {
  return new Competitor({
    userId: req.userId,
    name: comp.name,
    url: comp.url,
    reason: comp.reason,
    similarity: comp.similarity,
    source: 'ai',
    selected: false,
    urlAnalysisId: urlAnalysis._id  // âœ… Linked to analysis
  }).save();
});
```

**Data Points Stored**:
- `userId`: Owner of the competitor
- `urlAnalysisId`: Links competitor to the specific analysis
- `name`: Competitor company name
- `url`: Competitor website URL
- `reason`: Why this competitor was identified
- `similarity`: 'High', 'Medium', or 'Low'
- `source`: 'ai' (generated by AI analysis)
- `selected`: `false` initially (user selects later)

#### 2.2 Topics Storage
```javascript
// Lines 399-418
analysisResults.topics.map(topic => {
  return new Topic({
    userId: req.userId,
    name: topic.name,
    description: topic.description,
    keywords: topic.keywords || [],
    priority: topic.priority,
    source: 'ai',
    selected: false,
    urlAnalysisId: urlAnalysis._id  // âœ… Linked to analysis
  }).save();
});
```

**Data Points Stored**:
- `userId`: Owner of the topic
- `urlAnalysisId`: Links topic to the specific analysis
- `name`: Topic name (e.g., "Cloud Infrastructure")
- `description`: Detailed description of the topic
- `keywords`: Array of relevant keywords
- `priority`: 'High', 'Medium', or 'Low'
- `source`: 'ai' or 'user'
- `selected`: `false` initially
- `promptCount`: Number of prompts generated for this topic (default: 0)

#### 2.3 Personas Storage
```javascript
// Lines 421-436
analysisResults.personas.map(persona => {
  return new Persona({
    userId: req.userId,
    type: persona.type,
    description: persona.description,
    painPoints: persona.painPoints || [],
    goals: persona.goals || [],
    relevance: persona.relevance,
    source: 'ai',
    selected: false,
    urlAnalysisId: urlAnalysis._id  // âœ… Linked to analysis
  }).save();
});
```

**Data Points Stored**:
- `userId`: Owner of the persona
- `urlAnalysisId`: Links persona to the specific analysis
- `type`: Persona type (e.g., "Enterprise CTO")
- `description`: Detailed persona description
- `painPoints`: Array of pain points
- `goals`: Array of goals
- `relevance`: 'High', 'Medium', or 'Low'
- `source`: 'ai' or 'user'
- `selected`: `false` initially

---

### User Selection Update (Before Generate Prompts)

**Location**: `/backend/src/routes/onboarding.js` â†’ `/update-selections` endpoint (lines 588-717)

**Flow**:
1. Frontend sends selected competitor URLs, topic names, and persona types
2. Backend resets all selections for the current `urlAnalysisId`:
   ```javascript
   const resetQuery = { userId };
   if (urlAnalysisId) {
     resetQuery.urlAnalysisId = urlAnalysisId;
   }
   await Competitor.updateMany(resetQuery, { selected: false });
   await Topic.updateMany(resetQuery, { selected: false });
   await Persona.updateMany(resetQuery, { selected: false });
   ```
3. For each selected item, backend:
   - Tries to find existing item by matching:
     - Competitors: Match by `url`
     - Topics: Match by `name`
     - Personas: Match by `type`
   - Updates `selected: true` and `urlAnalysisId` if found
   - Creates new document if not found (for user-added items)

**âš ï¸ CRITICAL ISSUE #1**: The matching logic uses `name` and `type` for topics/personas, which can fail if:
- Names don't match exactly (case sensitivity, whitespace, etc.)
- User adds custom topics/personas with different names
- AI-generated names differ from stored names

---

## 3. Prompt Generation & Storage

### 3.1 Generate Prompts Endpoint

**Location**: `/backend/src/routes/onboarding.js` â†’ `/generate-prompts` endpoint (lines 720-925)

**Flow**:
1. **Get Latest Analysis** (lines 735-743):
   ```javascript
   const latestAnalysis = await UrlAnalysis.findOne({ userId })
     .sort({ analysisDate: -1 });
   ```
   âš ï¸ **CRITICAL ISSUE #2**: Uses `userId` only, not `urlAnalysisId`. If user has multiple analyses, it gets the latest one, which might not be the one the user is currently working with.

2. **Get Selected Items** (lines 745-748):
   ```javascript
   const selectedCompetitors = await Competitor.find({ 
     userId, 
     selected: true, 
     urlAnalysisId: latestAnalysis._id 
   });
   const selectedTopics = await Topic.find({ 
     userId, 
     selected: true, 
     urlAnalysisId: latestAnalysis._id 
   });
   const selectedPersonas = await Persona.find({ 
     userId, 
     selected: true, 
     urlAnalysisId: latestAnalysis._id 
   });
   ```
   âœ… This correctly filters by `urlAnalysisId`.

3. **Prepare Prompt Data** (lines 754-774):
   - Maps topics to include `_id`, `name`, `description`, `keywords`
   - Maps personas to include `_id`, `type`, `description`, `painPoints`, `goals`
   - Extracts brand context from `latestAnalysis.brandContext`
   - Sets `totalPrompts: 20` (20 prompts per topic-persona combination)

4. **Generate Prompts** (line 789):
   ```javascript
   const generatedPrompts = await promptGenerationService.generatePrompts(promptData);
   ```
   This calls the AI service to generate prompts.

### 3.2 Prompt Generation Service

**Location**: `/backend/src/services/promptGenerationService.js`

**Process**:
1. **For each topic-persona combination**:
   - Generates `20 prompts per combination` (default)
   - Over-generates by 2x (40 prompts) to account for deduplication
   - Calls OpenRouter API with GPT-4o to generate prompts

2. **Deduplication**:
   - **Step 1**: Deduplicates within each combination
   - **Step 2**: Cross-combination deduplication
   - Uses Levenshtein distance, word similarity, and substring matching
   - Ensures each combination gets exactly 20 unique prompts

3. **Returns Array**:
   ```javascript
   {
     topicId: topic._id,
     personaId: persona._id,
     topicName: topic.name,
     personaType: persona.type,
     promptText: "Generated prompt text...",
     queryType: "Commercial" // All are Commercial TOFU
   }
   ```

### 3.3 Prompt Storage

**Location**: `/backend/src/routes/onboarding.js` â†’ `/generate-prompts` endpoint (lines 794-852)

**Flow**:
```javascript
for (const promptData of generatedPrompts) {
  // Find topic and persona by name/type (NOT by _id!)
  const topic = selectedTopics.find(t => t.name === promptData.topicName);
  const persona = selectedPersonas.find(p => p.type === promptData.personaType);

  const prompt = new Prompt({
    userId,
    topicId: topic._id,      // Reference to Topic document
    personaId: persona._id,  // Reference to Persona document
    title: `${topic.name} Ã— ${persona.type} - ${promptData.queryType}`,
    text: promptData.promptText,
    queryType: promptData.queryType,
    status: 'active',
    metadata: {
      generatedBy: 'ai',
      targetPersonas: [persona.type],
      targetCompetitors: selectedCompetitors.filter(c => c.name).map(c => c.name)
    }
  });
  
  await prompt.save();
}
```

**âš ï¸ CRITICAL ISSUE #3**: Prompts are matched by `name` and `type` instead of using the `_id` that was already in the prompt data:
- The prompt generation service returns `topicId` and `personaId` (which are MongoDB ObjectIds)
- But the storage code ignores these and re-matches by `name`/`type`
- This can cause mismatches if names don't match exactly

**âš ï¸ CRITICAL ISSUE #4**: **Prompts don't have `urlAnalysisId` field!**
- The `Prompt` model has no `urlAnalysisId` field
- Prompts are only linked indirectly via `topicId` â†’ `Topic.urlAnalysisId` and `personaId` â†’ `Persona.urlAnalysisId`
- This makes it impossible to:
  - Directly query prompts for a specific analysis
  - Ensure prompts belong to the correct analysis
  - Handle cases where same topic/persona exists in multiple analyses

**Data Points Stored in Prompt**:
- `userId`: Owner of the prompt
- `topicId`: Reference to Topic document (ObjectId)
- `personaId`: Reference to Persona document (ObjectId)
- `title`: Generated title (e.g., "Cloud Infrastructure Ã— Enterprise CTO - Commercial")
- `text`: The actual prompt text
- `queryType`: "Commercial" (all are Commercial TOFU)
- `status`: "active" or "archived"
- `metadata.generatedBy`: "ai" or "user"
- `metadata.targetPersonas`: Array of persona types
- `metadata.targetCompetitors`: Array of competitor names
- `performance.tested`: Whether prompt has been tested
- `performance.successRate`: Success rate (0-100)
- `performance.llmResults`: Array of test results per LLM platform

---

## 4. Post-Generation: Testing & Metrics

After prompts are saved, the system automatically:
1. **Tests all prompts** across LLM platforms (ChatGPT, Claude, Gemini, Perplexity)
2. **Calculates metrics** (visibility, citations, etc.)
3. **Aggregates metrics** by platform, topic, persona

**Location**: Lines 856-898 in `/generate-prompts` endpoint

---

## 5. Architectural Flaws Summary

### ğŸ”´ **FLAW #1: Missing `urlAnalysisId` in Prompts**
**Impact**: High
- Prompts cannot be directly queried by analysis
- Risk of data leakage between analyses
- Difficult to clean up prompts for a specific analysis

**Solution**: Add `urlAnalysisId` field to Prompt model and set it during creation.

### ğŸ”´ **FLAW #2: Name/Type Matching Instead of ID**
**Impact**: High
- Prompts are matched by `name`/`type` instead of using the `_id` from prompt generation
- Can fail if names don't match exactly (whitespace, case, etc.)
- The prompt generation service already returns `topicId` and `personaId`, but they're ignored

**Solution**: Use the `topicId` and `personaId` directly from generated prompts instead of re-matching.

### ğŸ”´ **FLAW #3: Latest Analysis Assumption**
**Impact**: Medium
- The `/generate-prompts` endpoint uses `latestAnalysis` by `analysisDate`
- If user has multiple analyses, it might use the wrong one
- Frontend should pass `urlAnalysisId` explicitly

**Solution**: Accept `urlAnalysisId` as a parameter and use it instead of querying for latest.

### ğŸ”´ **FLAW #4: Fragile Matching in update-selections**
**Impact**: Medium
- Topics matched by `name`, personas by `type`
- Can create duplicates if names don't match exactly
- No validation of exact matches

**Solution**: Use IDs from frontend or implement fuzzy matching with validation.

### ğŸŸ¡ **FLAW #5: No Transaction Management**
**Impact**: Medium
- If prompt generation fails midway, partial data might be saved
- No rollback mechanism

**Solution**: Wrap in database transactions.

### ğŸŸ¡ **FLAW #6: Embedded vs Separate Documents**
**Impact**: Low
- `UrlAnalysis` has embedded `competitors`, `topics`, `personas` arrays
- But also creates separate `Competitor`, `Topic`, `Persona` documents
- Data duplication and potential inconsistency

**Solution**: Either use embedded documents OR separate documents, but not both.

---

## 6. Recommended Fixes

### Priority 1: Add `urlAnalysisId` to Prompts
```javascript
// In Prompt model
urlAnalysisId: {
  type: mongoose.Schema.Types.ObjectId,
  ref: 'UrlAnalysis',
  index: true
}

// In prompt creation
const prompt = new Prompt({
  userId,
  urlAnalysisId: latestAnalysis._id,  // ADD THIS
  topicId: topic._id,
  personaId: persona._id,
  // ... rest
});
```

### Priority 2: Use IDs from Generated Prompts
```javascript
// Instead of matching by name/type:
const topic = selectedTopics.find(t => t.name === promptData.topicName);

// Use the ID directly:
const topic = selectedTopics.find(t => t._id.toString() === promptData.topicId.toString());
```

### Priority 3: Accept `urlAnalysisId` Parameter
```javascript
router.post('/generate-prompts', authenticateToken, asyncHandler(async (req, res) => {
  const { urlAnalysisId } = req.body;  // Accept from frontend
  
  const targetAnalysis = urlAnalysisId 
    ? await UrlAnalysis.findById(urlAnalysisId)
    : await UrlAnalysis.findOne({ userId }).sort({ analysisDate: -1 });
    
  // Use targetAnalysis instead of latestAnalysis
}));
```

### Priority 4: Improve Matching Logic
- Use fuzzy matching for names
- Validate matches before creating new documents
- Log warnings for potential mismatches

---

## 7. Data Flow Diagram

```
User clicks "Generate Prompts"
    â†“
Frontend: handleGeneratePrompts()
    â†“
1. Update Selections â†’ /update-selections
   - Updates selected: true for competitors/topics/personas
   - Matches by URL/name/type
   â†“
2. Generate Prompts â†’ /generate-prompts
   - Gets latestAnalysis (by userId only) âš ï¸
   - Gets selected items (filtered by urlAnalysisId) âœ…
   - Calls promptGenerationService.generatePrompts()
   - Generates prompts via OpenRouter API
   - Saves prompts to database (matched by name/type) âš ï¸
   - Tests prompts automatically
   - Calculates metrics
   â†“
3. Response to Frontend
   - Returns saved prompts
   - Redirects to dashboard
```

---

## 8. Current Data Relationships

```
User
  â”œâ”€â”€ UrlAnalysis (has _id = urlAnalysisId)
  â”‚     â”œâ”€â”€ Embedded: competitors[], topics[], personas[]
  â”‚     â””â”€â”€ brandContext, productContext, etc.
  â”‚
  â”œâ”€â”€ Competitor (separate collection)
  â”‚     â”œâ”€â”€ urlAnalysisId â†’ UrlAnalysis
  â”‚     â””â”€â”€ selected: true/false
  â”‚
  â”œâ”€â”€ Topic (separate collection)
  â”‚     â”œâ”€â”€ urlAnalysisId â†’ UrlAnalysis
  â”‚     â””â”€â”€ selected: true/false
  â”‚
  â”œâ”€â”€ Persona (separate collection)
  â”‚     â”œâ”€â”€ urlAnalysisId â†’ UrlAnalysis
  â”‚     â””â”€â”€ selected: true/false
  â”‚
  â””â”€â”€ Prompt (separate collection)
        â”œâ”€â”€ topicId â†’ Topic
        â”œâ”€â”€ personaId â†’ Persona
        â””â”€â”€ âŒ NO urlAnalysisId (FLAW!)
```

---

## Conclusion

The current architecture has several critical flaws that can lead to:
- Data isolation issues (prompts not properly linked to analyses)
- Matching failures (name/type mismatches)
- Wrong analysis being used (latest analysis assumption)
- Difficulty in querying and managing prompts per analysis

The recommended fixes should be implemented to ensure data integrity and proper isolation between multiple analyses per user.

